{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.21.0\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "print(selenium.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from excel\n",
    "# Read the Excel file\n",
    "file_path = '../cities_scrap2.xlsx'  # Replace with your file path\n",
    "sheet_name = 'Test'  # Replace with your sheet name\n",
    "column_name_city = 'city'  # Replace with your column name\n",
    "column_name_country = 'country'  # Replace with your column name\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Convert the column to a list\n",
    "city_list = df[column_name_city].tolist()\n",
    "country_list = df[column_name_country].tolist()\n",
    "\n",
    "# final list\n",
    "city_names = []\n",
    "for idx,city in enumerate(city_list):\n",
    "    city_names.append(city_list[idx])\n",
    "    city_names.append(str(city_list[idx])+'-'+str(country_list[idx]))\n",
    "\n",
    "# city_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(city_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver\n",
    "\n",
    "# Set up Chrome options to run in headless mode\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "# Set up the WebDriver with the Chrome options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "# driver = webdriver.Chrome()  # Assuming you're using Chrome\n",
    "\n",
    "# Base URL\n",
    "url_base = 'https://www.numbeo.com/quality-of-life/in/'\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df_capital_all = pd.DataFrame(columns=[\n",
    "    'index',\n",
    "    'city',\n",
    "    'climate_index',\n",
    "    'cost_of_living_index',\n",
    "    'health_care_index',\n",
    "    'pollution_index',\n",
    "    'property_price_to_income_ratio',\n",
    "    'purchasing_power_index',\n",
    "    'safety_index',\n",
    "    'traffic_commute_time_index',\n",
    "    'quality_of_life_index'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data using Selenium\n",
    "\n",
    "for idx,city in enumerate(city_names):\n",
    "\n",
    "    try:\n",
    "\n",
    "        url_city = url_base + city_names[idx]\n",
    "        driver.get(url_city)\n",
    "\n",
    "        # Find Table element\n",
    "        tbl_quality = driver.find_element(By.XPATH, '/html/body/div[2]/table')  # if there's no ID, always a good idea to copy xpath\n",
    "\n",
    "        \n",
    "        # Parse Table element into pandas DataFrame\n",
    "        tbl_quality_html = tbl_quality.get_attribute('outerHTML')\n",
    "        soup = BeautifulSoup(tbl_quality_html, 'html.parser')\n",
    "\n",
    "        # Find all table rows in the parsed HTML\n",
    "        tbl_quality_rows = soup.find_all('tr')\n",
    "\n",
    "        # Initialize data list\n",
    "        data_cost = []\n",
    "        for row in tbl_quality_rows:\n",
    "                row_data = []\n",
    "                cells = row.find_all(['td', 'th'])\n",
    "                for cell in cells:\n",
    "                    row_data.append(cell.get_text().strip())\n",
    "                data_cost.append(row_data)\n",
    "\n",
    "        # Extract header and data rows separately\n",
    "        header = ['kpi_name','kpi_value','kpi_hml']\n",
    "\n",
    "        # Create DataFrame\n",
    "        df_capital = pd.DataFrame(data_cost, columns=header)\n",
    "\n",
    "        # Clean data\n",
    "        df_capital['Index'] = idx\n",
    "        df_capital['City'] = city_names[idx]\n",
    "        df_capital.drop(columns=['kpi_hml'], inplace=True)\n",
    "        df_capital['kpi_value'] = pd.to_numeric(df_capital['kpi_value'], errors='coerce')\n",
    "        # df_capital = df_capital[~df_capital['kpi_name'].isna()].copy()\n",
    "        df_capital.drop(8, inplace=True)\n",
    "\n",
    "\n",
    "        # Transpose df\n",
    "        df_capital_t = df_capital.pivot_table(index=['Index','City'], columns='kpi_name', values='kpi_value', dropna=False)\n",
    "        df_capital_t.reset_index(inplace=True)\n",
    "        df_capital_t.columns = df_capital_all.columns\n",
    "\n",
    "        # Append data to complete DF\n",
    "        df_capital_all = pd.concat([df_capital_all,df_capital_t], axis=0)\n",
    "\n",
    "    except:\n",
    "         print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capital_all.head(20)\n",
    "# df_capital_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capital_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capital_all.to_csv('test_out_final_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the file path\n",
    "# file_path = r'C:\\Users\\paude\\Documents\\00. Backup 2023\\EXTERIOR\\MASTER\\MA IAAC\\03. Cursada\\01. Modulo 03\\S01 DE\\Class Project\\DE_Team\\Scraped_csvs\\data_cost.csv'\n",
    "\n",
    "# # Export DataFrame to a CSV file\n",
    "# df_capital_2.to_csv(file_path, index=False)\n",
    "\n",
    "# print(\"DataFrame exported successfully to:\", file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
